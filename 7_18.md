# July 18th Lecture

## Single Trial (Bernoulli Trial)
- The simplest situation with uncertainty is a single experiment, where the outcome is **either success or failure** - the result is binary
- Since there is a binary outcome, the random variable $X$ is defined to be either 0 or 1
    - $X = 1$ if success is observed: $P(X=1) = p$
    - $X = 0$ if failure is observed: $P(X=0) = 1 - p$
    - These outcomes are mutually exclusive and collectively exhaustive
- The probability mass function for this random variable is:
    $p_X(x)=\{p: x = 1, 1-p:x = 0\}$
- The mean value of this probability distribution can be found to be:
    - $E[X]=\sum_{x_i}x_i \cdot p_x(x_i)$
    - $E[X] = 1(p)+0(1-p)=p$
- The variance of this probability distribution can be found to be:
    - $Var[X]=E[(X-\mu_X)^2] = \sum_{x_i}(x_i-\mu_X)^2 \cdot p_X(x_i)$
    - $Var[X] = (1-p)^2p + (0-p)^2(1-p)$
    - $Var[X] = (1-p)p$
## Repeated Trials: Binomial Distribution of Bernoulli Sequence
- Consider $n$ repeated trials, each of which are still binary in outcome (either success or failure), have the same probability of success $p$, and are independent of each other
- The number of successes $X$ (the random variable) in $n$ repeated trials follows a **Binomial Distribution**
- The probability mass function for $X$ is:
    - $p_X(x)=(^{n}_{x})p^x(1-p)^{n-x}$ where $x = 0, 1,...,n$
        - $(^n _x) = \frac{n!}{x!(n-x)!}$
        - The $p^x$ term represents the probability of $x$ successes and the $(1-p)^{n-x}$ term represents the probability of $n-x$ failures; the combination term accounts for all possible permutations (orderings) of $x$ successes
- The mean (expected) value of this probability distribution is:
    - $\mu_X=E[X] = np$
        - $\mu_X=\sum_{i=1}^n 1(p) + \sum_{i=1}^n 0(1-p)=np$
- The variance of this probability distribution is:
    - $\sigma_X^2=np(1-p)$
- Example: You are using five road graders on a highway construction project. Each grader will be in constant use during the project, which is expected to take 2000 hours. The probability tghat the individual grader fails within 2000 hours is 0.05. The failure of the five graders is jointly independent. Find the probability that two graders will fail during the project.
    - $p(X=2)= (^{5}_{2})(0.05^2)(1-0.05)^{5-2}$
- Summary Reference:
    - $\mu_X = np$
    - $\sigma_X = \sqrt{np(1-p)}$
    - $\delta_X = \sqrt{\frac{1-p}{np}}$
    - $\gamma_X = \frac{1-2p}{\sqrt{np(1-p)}}$
## Repeated Trials: The Geometric Distribution
- The Geometric Distribution considers at what trial the *first success occurs*, though it is still assumed that successive trials are independent and the probability of success is a constant value
- The first success will occur on the $nth$ trial if and only if the first $n - 1$ trials are failures and the $nth$ trial is a success; therefore, the probability mass function is:
    - $p_N(n)= p(1-p)^{n-1}$
- The CDF of the Geometric Distribution indicates that the first success will occur by trial $n$ (the number of trials to the first success is less than or equal to $n$)
    - $F_N(n) = P(N \leq n) = 1 - P(no \; success \; in \; n \; trials)$
    - $F_N(n) = 1 - (^n_0)p^0(1-p)^n$
        - The Binomial PMF is used for the case of 0 successes and all failures 
    - $F_N(n) = 1 - (1 - p)^n$
- Summary Reference:
    - $\mu_N = \frac{1}{p}$
    - $\sigma_N = \frac{\sqrt{1-p}}{p}$
    - $\delta_N = \sqrt{1-p}$
- Example: An engineer has designed a flood protection system and computed its capacity. She estimates that there is a probability of $p = 0.02$ that a flood greater than the system capacity will occur in a given year. What is the expected value $N$, the time to the first occurence of a flood? What is the probability that at least one flood greater than the system capacity will occur within the 30-year design lifetime of the system?
    - i): $\mu_N = 1/p = 50$ years
    - ii): $P(N\leq30) = 1-(1-p)^N = 1 - (1 - 0.02)^{30} = 0.45 $
## Return Periods
- The mean value of the time to the first event with probability $p$ is $1/p$ (geometric distribution) - this is known as the **average return period** (or just **return period**)
    - An event with return period of $m$ years indicates that the event can occur any year with probability $1/m$
## Repeated Trials: Negative Binomial Distribution
- The Geomtric Distribution is concerned with the number of trials until the *first success*; the Negative Binomial Distribution is concerned with the number of trials to the *kth success*
- Denoting $W_k$ as the trial at which the *kth* success occurs, it can be shown to be represented as a sum of intervals
    - $W_k = N_1 + N_2 + N_3 + N_4 + .. + N_k$
    - Each $N_i$ represents the number of trials between the $i-1$th and $ith$ successes
- The PMF is:
    - $p_{W_k}(w) = (^{w-1}_{k - 1})p^k(1-p)^{w-k}$
- $E[W_k] = E[N_1 + N_2 + .. + N_k]$
    - $E[W_k] = E[N_1] + E[N_2] + .. + E[N_k]$
    - $E[W_k] = \frac{1}{p} + \frac{1}{p} + ... + \frac{1}{p} = \frac{k}{p}$
- Since the trials are independent, the $N_i$ are also independent random variables, each having a geometric distribution with parameter $p$ - this can be used to find the mean and standard deviation of $W_k$
    - $\mu_{W_k} = \frac{k}{p}$
    - $\sigma_{W_k} = \frac{\sqrt{k(1-p)}}{p}$
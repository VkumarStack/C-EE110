# July 20th Lecture
- The aforementioned Bernoulli Trials were discrete by nature, but there are many cases with similar phenomenon but continuous random variables
    - This can be considered with an infinitely large number of trials
## Counting Events: Poisson Distribution
- Recall the binomial distribution, which represents the number of successes in $N$ trials:
    - $p_X(x) = (^n_x)p^x(1-p)^{n-x}$
- If $n \rightarrow \infty$ and $p \rightarrow 0$ such that $np \rightarrow v$, then:
    - $p_X(x) = \frac{v^x}{x!}e^{-v}$
- Moments:
    - Mean: $\mu_X = v$
    - Standard Deviation: $\sigma_X = \sqrt{v}$
    - Coefficient of Skewness: $\gamma_X = \frac{1}{\sqrt{v}}$
- Note that the Poisson Distribution has only one parameter, $v$
    - This parameter represents the expected number of events in some period *t*
    - The parameter is often written as $\lambda t$ rather than $v$ to reflect this, where $\lambda$ represents the mean rate of success (events) per unit of time
- It is a property of the Poisson distribution that the *sum of two Poisson random variables is also Poisson*
    - $v = v_1 +v_2$
## Poisson Process
- The Poisson process is a random function of time (or space), or a **stochastic process**, whose value at time $t$, $X(t)$, is the (random) number of arrivals or incidents that have occurred since $t = 0$
    - At any fixed time $t_0$, the probability distribution of the number of incidents that have occurred $X(t_0)$ is modeled using the Poisson distribution
    - Here, the observation of a random process are *sample functions* $x_1(t), x_2(t), ..., x_n(t) $
- The random variable $X(t_0)$ has a Poisson distribution with parameter $\lambda t_0$ if the stochastic process is a Poisson process with parameter $\lambda$:
    - **Stationarity**: The probability of an event in a short time interval from time t to t + h is approximately $\lambda h$ for any t
    - **Nonmultiplicity**: The probability of two or more events in a short interval of time is negligible compared to $\lambda h$
    - **Independence**: The number of events in any interval of time is independent of the number of events in any other (non-overlapping) interval of time
## Exponential Distribution
- The Poisson Distribution primarily deals with the number of events in a given time interval; the Exponential Distribution is concerned with the amount of time *between events*
- If the process is represented by a Poisson process, then its distribution is:
    - Let the time to the first event be $T$
    - $P(T > t) = P(no \; events \; in \; time \; t)$
        - $P(T > t) = P(X = 0) = \frac{(\lambda t)^0}{0!}e^{-\lambda t} = e^{-\lambda t}$
    - CDF: $F_T(t) = P(T \leq t) = 1 - e^{-\lambda t}$
        - PDF: $f_T = \frac{d}{dt}F_T(t) = \lambda e^{-\lambda t}$
- This distribution describes the time to the first occurrence of a Poisson event, but because a Poisson process is stationary and independent, this can just be represented as the time to the next event
- Moments:
    - $\mu_T = \frac{1}{\lambda}$
    - $\sigma_T = \frac{1}{\lambda}$
    - $\delta_T = 1$
## Gamma Distribution
- The exponential distribution can be generalized to determine the probability distribution of the time until the $kth$ event in a Poisson process
- PDF: $f_T(t) = \frac{\lambda (\lambda t)^{k - 1}}{(k - 1)!}e^{-\lambda t}$
    - k does not necessarily need to be an integer, so the gamma function can be used to compute factorials of non-integer k-values (so long as k is positive)
    - $f_X(x)=\frac{\lambda(\lambda x)^{k - 1}}{\Gamma (k)}e^{-\lambda x}$
    - $F_X(x) = \frac{\Gamma (\lambda x, k)}{\Gamma k}$
        - $\Gamma(k) = \int_0^\infty e^{-u}u^{k - 1}du$
        - $\Gamma(\lambda x, k) = \int_0^{\lambda x } e^{-u}u^{k - 1}du$
- Moments:
    - $\mu_X = \frac{k}{\lambda}$
    - $\sigma_X = \frac{\sqrt{k}}{\lambda}$
    - $\gamma_X = \frac{2}{\sqrt{k}}$